{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Inputs:\n",
      "Shape = (56000, 784)\n",
      "Minimum = 0.0\n",
      "Maximum = 1.0\n",
      "Range = 1.0\n",
      "Variance = 0.09523605\n",
      "Standard Deviation = 0.30860338\n",
      "\n",
      "Testing Inputs:\n",
      "Shape = (14000, 784)\n",
      "Minimum = 0.0\n",
      "Maximum = 1.0\n",
      "Range = 1.0\n",
      "Variance = 0.09475792\n",
      "Standard Deviation = 0.30782774\n",
      "\n",
      "Training Outputs:\n",
      "Shape = (56000, 10)\n",
      "Minimum = 0.0\n",
      "Maximum = 1.0\n",
      "Range = 1.0\n",
      "Variance = 0.09000002\n",
      "Standard Deviation = 0.30000004\n",
      "\n",
      "Testing Outputs:\n",
      "Shape = (14000, 10)\n",
      "Minimum = 0.0\n",
      "Maximum = 1.0\n",
      "Range = 1.0\n",
      "Variance = 0.09\n",
      "Standard Deviation = 0.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import utils\n",
    "from keras import Input\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# MNIST dataset params\n",
    "num_classes = 10 # 0-9 digits\n",
    "num_features = 784 # img shape: 28*28\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# convert to float32\n",
    "X_train = np.array(X_train, np.float32)\n",
    "X_test = np.array(X_test, np.float32)\n",
    "\n",
    "# concatenate all data\n",
    "X = np.concatenate([X_train, X_test])\n",
    "y = np.concatenate([y_train, y_test])\n",
    "\n",
    "# shuffle data\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "\n",
    "# vectorize images\n",
    "X_train = X_train.reshape([-1, num_features])\n",
    "X_test = X_test.reshape([-1, num_features])\n",
    "\n",
    "# normalize images values from [0, 255] to [0, 1]\n",
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255.\n",
    "\n",
    "# Convert target classes to categorical ones (one-hot encoding)\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "print(\"Training Inputs:\")\n",
    "utils.data_summary(X_train)\n",
    "\n",
    "print(\"Testing Inputs:\")\n",
    "utils.data_summary(X_test)\n",
    "\n",
    "print(\"Training Outputs:\")\n",
    "utils.data_summary(y_train)\n",
    "\n",
    "print(\"Testing Outputs:\")\n",
    "utils.data_summary(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_Adam\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer_1 (Dense)      (None, 128)               100480    \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 256)               33024     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136,074\n",
      "Trainable params: 136,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# network params\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 256\n",
    "\n",
    "# create model\n",
    "mlp_adam = keras.Sequential(name=\"MLP_Adam\")\n",
    "mlp_adam.add(Input(shape=(num_features,)))\n",
    "mlp_adam.add(keras.layers.Dense(name=\"hidden_layer_1\", units=n_hidden_1, activation=\"relu\"))\n",
    "mlp_adam.add(keras.layers.Dense(name=\"hidden_layer_2\", units=n_hidden_2, activation=\"relu\"))\n",
    "mlp_adam.add(keras.layers.Dense(name=\"output_layer\", units=num_classes, activation=\"softmax\"))\n",
    "\n",
    "mlp_adam.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "219/219 [==============================] - 2s 5ms/step - loss: 0.3812 - accuracy: 0.8942 - val_loss: 0.1862 - val_accuracy: 0.9466\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1396 - accuracy: 0.9593 - val_loss: 0.1309 - val_accuracy: 0.9611\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0964 - accuracy: 0.9713 - val_loss: 0.1109 - val_accuracy: 0.9664\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0728 - accuracy: 0.9778 - val_loss: 0.1029 - val_accuracy: 0.9690\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0577 - accuracy: 0.9824 - val_loss: 0.0962 - val_accuracy: 0.9717\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0453 - accuracy: 0.9860 - val_loss: 0.0970 - val_accuracy: 0.9709\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0350 - accuracy: 0.9892 - val_loss: 0.0913 - val_accuracy: 0.9735\n",
      "Epoch 8/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.0887 - val_accuracy: 0.9763\n",
      "Epoch 9/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9930 - val_loss: 0.0876 - val_accuracy: 0.9774\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.0880 - val_accuracy: 0.9761\n",
      "Epoch 11/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.0927 - val_accuracy: 0.9766\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.0974 - val_accuracy: 0.9763\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.0974 - val_accuracy: 0.9769\n",
      "Epoch 14/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 0.1027 - val_accuracy: 0.9771\n",
      "Epoch 15/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0986 - val_accuracy: 0.9779\n",
      "Epoch 16/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.1086 - val_accuracy: 0.9771\n",
      "Epoch 17/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.1151 - val_accuracy: 0.9764\n",
      "Epoch 18/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.1209 - val_accuracy: 0.9750\n",
      "Epoch 19/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.1339 - val_accuracy: 0.9731\n",
      "Epoch 20/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.1125 - val_accuracy: 0.9771\n",
      "Epoch 21/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.1216 - val_accuracy: 0.9769\n",
      "Epoch 22/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.1202 - val_accuracy: 0.9766\n",
      "Epoch 23/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1183 - val_accuracy: 0.9771\n",
      "Epoch 24/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.1248 - val_accuracy: 0.9781\n",
      "Epoch 25/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 9.9881e-04 - accuracy: 0.9999 - val_loss: 0.1162 - val_accuracy: 0.9798\n",
      "Epoch 26/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.9176e-04 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9802\n",
      "Epoch 27/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.0755e-04 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9805\n",
      "Epoch 28/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.6074e-04 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9806\n",
      "Epoch 29/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.3608e-04 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9804\n",
      "Epoch 30/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.2065e-04 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9806\n",
      "Epoch 31/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.0818e-04 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9809\n",
      "Epoch 32/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 9.7070e-05 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9806\n",
      "Epoch 33/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 8.8071e-05 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9807\n",
      "Epoch 34/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 7.9132e-05 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9804\n",
      "Epoch 35/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 7.2291e-05 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9806\n",
      "Epoch 36/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 6.5195e-05 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9807\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 6.1500e-05 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9806\n",
      "Epoch 38/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 5.4243e-05 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9809\n",
      "Epoch 39/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 4.9221e-05 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9806\n",
      "Epoch 40/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 4.4296e-05 - accuracy: 1.0000 - val_loss: 0.1317 - val_accuracy: 0.9808\n",
      "Epoch 41/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 4.0398e-05 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9804\n",
      "Epoch 42/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 3.6265e-05 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9806\n",
      "Epoch 43/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 3.3130e-05 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9809\n",
      "Epoch 44/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 3.0173e-05 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9806\n",
      "Epoch 45/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.6648e-05 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9806\n",
      "Epoch 46/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.4530e-05 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9809\n",
      "Epoch 47/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.2046e-05 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9805\n",
      "Epoch 48/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.0364e-05 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9805\n",
      "Epoch 49/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.8223e-05 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9808\n",
      "Epoch 50/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.6569e-05 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9805\n",
      "Epoch 51/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.9937 - val_loss: 0.2119 - val_accuracy: 0.9616\n",
      "Epoch 52/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9901 - val_loss: 0.1171 - val_accuracy: 0.9776\n",
      "Epoch 53/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1287 - val_accuracy: 0.9779\n",
      "Epoch 54/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.1251 - val_accuracy: 0.9794\n",
      "Epoch 55/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1261 - val_accuracy: 0.9788\n",
      "Epoch 56/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.7954e-04 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9801\n",
      "Epoch 57/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.5457e-04 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9800\n",
      "Epoch 58/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.2053e-04 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9800\n",
      "Epoch 59/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.0006e-04 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9803\n",
      "Epoch 60/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 8.5952e-05 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9803\n",
      "Epoch 61/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 7.4199e-05 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9804\n",
      "Epoch 62/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 6.4755e-05 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9803\n",
      "Epoch 63/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 5.7582e-05 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9804\n",
      "Epoch 64/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 5.0743e-05 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9804\n",
      "Epoch 65/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 4.5235e-05 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9804\n",
      "Epoch 66/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 4.0359e-05 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 0.9804\n",
      "Epoch 67/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 3.5789e-05 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9805\n",
      "Epoch 68/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 3.1907e-05 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9809\n",
      "Epoch 69/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.9090e-05 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9804\n",
      "Epoch 70/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.5944e-05 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9808\n",
      "Epoch 71/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.3412e-05 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9806\n",
      "Epoch 72/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.1033e-05 - accuracy: 1.0000 - val_loss: 0.1489 - val_accuracy: 0.9805\n",
      "Epoch 73/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.8903e-05 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9804\n",
      "Epoch 74/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.7065e-05 - accuracy: 1.0000 - val_loss: 0.1522 - val_accuracy: 0.9803\n",
      "Epoch 75/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.5440e-05 - accuracy: 1.0000 - val_loss: 0.1537 - val_accuracy: 0.9804\n",
      "Epoch 76/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.3822e-05 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9801\n",
      "Epoch 77/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.2474e-05 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9806\n",
      "Epoch 78/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.1293e-05 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 0.9806\n",
      "Epoch 79/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.0182e-05 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9804\n",
      "Epoch 80/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 9.1825e-06 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9804\n",
      "Epoch 81/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 8.2226e-06 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9804\n",
      "Epoch 82/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 7.4781e-06 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9804\n",
      "Epoch 83/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 6.7088e-06 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9803\n",
      "Epoch 84/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 6.0402e-06 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 0.9803\n",
      "Epoch 85/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 5.4461e-06 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9801\n",
      "Epoch 86/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 4.8792e-06 - accuracy: 1.0000 - val_loss: 0.1683 - val_accuracy: 0.9804\n",
      "Epoch 87/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 4.4046e-06 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9803\n",
      "Epoch 88/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 3.9227e-06 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9801\n",
      "Epoch 89/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 3.6210e-06 - accuracy: 1.0000 - val_loss: 0.1732 - val_accuracy: 0.9801\n",
      "Epoch 90/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 3.2139e-06 - accuracy: 1.0000 - val_loss: 0.1730 - val_accuracy: 0.9803\n",
      "Epoch 91/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.8738e-06 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9799\n",
      "Epoch 92/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.6156e-06 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9797\n",
      "Epoch 93/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.3516e-06 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9800\n",
      "Epoch 94/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.0935e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9798\n",
      "Epoch 95/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.8996e-06 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9801\n",
      "Epoch 96/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.6995e-06 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 0.9801\n",
      "Epoch 97/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.5170e-06 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9801\n",
      "Epoch 98/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.3564e-06 - accuracy: 1.0000 - val_loss: 0.1845 - val_accuracy: 0.9801\n",
      "Epoch 99/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.2191e-06 - accuracy: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9801\n",
      "Epoch 100/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.1033e-06 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "mlp_adam.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history = mlp_adam.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 4s 2ms/step - loss: 9.5376e-07 - accuracy: 1.0000\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1872 - accuracy: 0.9803\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# results\n",
    "train_results = mlp_adam.evaluate(X_train, y_train)\n",
    "test_results = mlp_adam.evaluate(X_test, y_test)\n",
    "\n",
    "loss_train = history.history[\"loss\"]\n",
    "loss_test = history.history[\"val_loss\"]\n",
    "\n",
    "accuracy_train = history.history[\"accuracy\"]\n",
    "accuracy_test = history.history[\"val_accuracy\"]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_train, label=\"loss train\")\n",
    "plt.plot(loss_test, label=\"loss test\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(accuracy_train, label=\"accuracy train\")\n",
    "plt.plot(accuracy_test, label=\"accuracy test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_RMSProp_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer_1 (Dense)      (None, 128)               100480    \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 256)               33024     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136,074\n",
      "Trainable params: 136,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# network params\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 256\n",
    "\n",
    "# create model\n",
    "mlp_rmsprop_1 = keras.Sequential(name=\"MLP_RMSProp_1\")\n",
    "mlp_rmsprop_1.add(Input(shape=(num_features,)))\n",
    "mlp_rmsprop_1.add(keras.layers.Dense(name=\"hidden_layer_1\", units=n_hidden_1, activation=\"relu\"))\n",
    "mlp_rmsprop_1.add(keras.layers.Dense(name=\"hidden_layer_2\", units=n_hidden_2, activation=\"relu\"))\n",
    "mlp_rmsprop_1.add(keras.layers.Dense(name=\"output_layer\", units=num_classes, activation=\"softmax\"))\n",
    "\n",
    "mlp_rmsprop_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "219/219 [==============================] - 2s 5ms/step - loss: 0.4309 - accuracy: 0.8787 - val_loss: 0.2164 - val_accuracy: 0.9366\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.1818 - accuracy: 0.9461 - val_loss: 0.1600 - val_accuracy: 0.9534\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.1311 - accuracy: 0.9615 - val_loss: 0.1408 - val_accuracy: 0.9586\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.1055 - accuracy: 0.9691 - val_loss: 0.1326 - val_accuracy: 0.9633\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0897 - accuracy: 0.9739 - val_loss: 0.1318 - val_accuracy: 0.9641\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0787 - accuracy: 0.9778 - val_loss: 0.1249 - val_accuracy: 0.9681\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0719 - accuracy: 0.9806 - val_loss: 0.1309 - val_accuracy: 0.9695\n",
      "Epoch 8/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0638 - accuracy: 0.9825 - val_loss: 0.1227 - val_accuracy: 0.9714\n",
      "Epoch 9/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0602 - accuracy: 0.9841 - val_loss: 0.1323 - val_accuracy: 0.9711\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0563 - accuracy: 0.9856 - val_loss: 0.1347 - val_accuracy: 0.9734\n",
      "Epoch 11/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0547 - accuracy: 0.9864 - val_loss: 0.1394 - val_accuracy: 0.9721\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0500 - accuracy: 0.9877 - val_loss: 0.1641 - val_accuracy: 0.9686\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0474 - accuracy: 0.9882 - val_loss: 0.1566 - val_accuracy: 0.9726\n",
      "Epoch 14/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0453 - accuracy: 0.9886 - val_loss: 0.1676 - val_accuracy: 0.9708\n",
      "Epoch 15/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0437 - accuracy: 0.9896 - val_loss: 0.1663 - val_accuracy: 0.9721\n",
      "Epoch 16/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0400 - accuracy: 0.9899 - val_loss: 0.1826 - val_accuracy: 0.9735\n",
      "Epoch 17/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0381 - accuracy: 0.9907 - val_loss: 0.1880 - val_accuracy: 0.9723\n",
      "Epoch 18/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0360 - accuracy: 0.9915 - val_loss: 0.2107 - val_accuracy: 0.9701\n",
      "Epoch 19/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0375 - accuracy: 0.9916 - val_loss: 0.1903 - val_accuracy: 0.9726\n",
      "Epoch 20/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0340 - accuracy: 0.9918 - val_loss: 0.2017 - val_accuracy: 0.9721\n",
      "Epoch 21/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0340 - accuracy: 0.9922 - val_loss: 0.2245 - val_accuracy: 0.9713\n",
      "Epoch 22/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0327 - accuracy: 0.9927 - val_loss: 0.2492 - val_accuracy: 0.9696\n",
      "Epoch 23/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9930 - val_loss: 0.2291 - val_accuracy: 0.9725\n",
      "Epoch 24/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9929 - val_loss: 0.2506 - val_accuracy: 0.9721\n",
      "Epoch 25/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9933 - val_loss: 0.2418 - val_accuracy: 0.9722\n",
      "Epoch 26/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0278 - accuracy: 0.9941 - val_loss: 0.2633 - val_accuracy: 0.9714\n",
      "Epoch 27/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0290 - accuracy: 0.9935 - val_loss: 0.2664 - val_accuracy: 0.9711\n",
      "Epoch 28/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0273 - accuracy: 0.9941 - val_loss: 0.2547 - val_accuracy: 0.9731\n",
      "Epoch 29/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9946 - val_loss: 0.2787 - val_accuracy: 0.9721\n",
      "Epoch 30/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0233 - accuracy: 0.9950 - val_loss: 0.2722 - val_accuracy: 0.9727\n",
      "Epoch 31/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9951 - val_loss: 0.3405 - val_accuracy: 0.9699\n",
      "Epoch 32/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9950 - val_loss: 0.3026 - val_accuracy: 0.9724\n",
      "Epoch 33/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 0.3357 - val_accuracy: 0.9696\n",
      "Epoch 34/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0236 - accuracy: 0.9952 - val_loss: 0.2929 - val_accuracy: 0.9719\n",
      "Epoch 35/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0223 - accuracy: 0.9956 - val_loss: 0.3131 - val_accuracy: 0.9727\n",
      "Epoch 36/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0183 - accuracy: 0.9962 - val_loss: 0.3129 - val_accuracy: 0.9726\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0200 - accuracy: 0.9957 - val_loss: 0.3529 - val_accuracy: 0.9702\n",
      "Epoch 38/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0203 - accuracy: 0.9958 - val_loss: 0.3165 - val_accuracy: 0.9727\n",
      "Epoch 39/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0205 - accuracy: 0.9957 - val_loss: 0.3705 - val_accuracy: 0.9690\n",
      "Epoch 40/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0190 - accuracy: 0.9963 - val_loss: 0.3473 - val_accuracy: 0.9720\n",
      "Epoch 41/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0172 - accuracy: 0.9968 - val_loss: 0.3796 - val_accuracy: 0.9705\n",
      "Epoch 42/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0156 - accuracy: 0.9968 - val_loss: 0.4196 - val_accuracy: 0.9709\n",
      "Epoch 43/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0165 - accuracy: 0.9968 - val_loss: 0.3763 - val_accuracy: 0.9732\n",
      "Epoch 44/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.3552 - val_accuracy: 0.9738\n",
      "Epoch 45/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0170 - accuracy: 0.9968 - val_loss: 0.3662 - val_accuracy: 0.9745\n",
      "Epoch 46/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0128 - accuracy: 0.9975 - val_loss: 0.4183 - val_accuracy: 0.9707\n",
      "Epoch 47/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.3811 - val_accuracy: 0.9731\n",
      "Epoch 48/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0138 - accuracy: 0.9973 - val_loss: 0.4098 - val_accuracy: 0.9711\n",
      "Epoch 49/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 0.5113 - val_accuracy: 0.9694\n",
      "Epoch 50/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0135 - accuracy: 0.9972 - val_loss: 0.4371 - val_accuracy: 0.9711\n",
      "Epoch 51/100\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.9980 - val_loss: 0.4032 - val_accuracy: 0.9736\n",
      "Epoch 52/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9977 - val_loss: 0.4308 - val_accuracy: 0.9724\n",
      "Epoch 53/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.9980 - val_loss: 0.4299 - val_accuracy: 0.9726\n",
      "Epoch 54/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.4325 - val_accuracy: 0.9725\n",
      "Epoch 55/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 0.4608 - val_accuracy: 0.9729\n",
      "Epoch 56/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9980 - val_loss: 0.4677 - val_accuracy: 0.9723\n",
      "Epoch 57/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9981 - val_loss: 0.4735 - val_accuracy: 0.9734\n",
      "Epoch 58/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.4832 - val_accuracy: 0.9729\n",
      "Epoch 59/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.4818 - val_accuracy: 0.9722\n",
      "Epoch 60/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 0.4951 - val_accuracy: 0.9743\n",
      "Epoch 61/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.4797 - val_accuracy: 0.9725\n",
      "Epoch 62/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.4796 - val_accuracy: 0.9726\n",
      "Epoch 63/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.4961 - val_accuracy: 0.9736\n",
      "Epoch 64/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.5026 - val_accuracy: 0.9715\n",
      "Epoch 65/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.5162 - val_accuracy: 0.9729\n",
      "Epoch 66/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.5049 - val_accuracy: 0.9741\n",
      "Epoch 67/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.5258 - val_accuracy: 0.9720\n",
      "Epoch 68/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.5225 - val_accuracy: 0.9728\n",
      "Epoch 69/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.5165 - val_accuracy: 0.9732\n",
      "Epoch 70/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.5413 - val_accuracy: 0.9732\n",
      "Epoch 71/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9986 - val_loss: 0.5299 - val_accuracy: 0.9724\n",
      "Epoch 72/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.5640 - val_accuracy: 0.9721\n",
      "Epoch 73/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.5919 - val_accuracy: 0.9702\n",
      "Epoch 74/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.5688 - val_accuracy: 0.9726\n",
      "Epoch 75/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.5640 - val_accuracy: 0.9725\n",
      "Epoch 76/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.5501 - val_accuracy: 0.9745\n",
      "Epoch 77/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.5472 - val_accuracy: 0.9730\n",
      "Epoch 78/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.5495 - val_accuracy: 0.9727\n",
      "Epoch 79/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.6142 - val_accuracy: 0.9721\n",
      "Epoch 80/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.5765 - val_accuracy: 0.9738\n",
      "Epoch 81/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.5549 - val_accuracy: 0.9741\n",
      "Epoch 82/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.6218 - val_accuracy: 0.9729\n",
      "Epoch 83/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.6015 - val_accuracy: 0.9731\n",
      "Epoch 84/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.5623 - val_accuracy: 0.9744\n",
      "Epoch 85/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.6129 - val_accuracy: 0.9732\n",
      "Epoch 86/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.6280 - val_accuracy: 0.9715\n",
      "Epoch 87/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5739 - val_accuracy: 0.9741\n",
      "Epoch 88/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.5748 - val_accuracy: 0.9746\n",
      "Epoch 89/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.6192 - val_accuracy: 0.9714\n",
      "Epoch 90/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.6031 - val_accuracy: 0.9737\n",
      "Epoch 91/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.6126 - val_accuracy: 0.9742\n",
      "Epoch 92/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 7.3946e-04 - accuracy: 0.9998 - val_loss: 0.6117 - val_accuracy: 0.9733\n",
      "Epoch 93/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.6845 - val_accuracy: 0.9729\n",
      "Epoch 94/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.5912 - val_accuracy: 0.9743\n",
      "Epoch 95/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.6195 - val_accuracy: 0.9734\n",
      "Epoch 96/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.6358 - val_accuracy: 0.9728\n",
      "Epoch 97/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.6556 - val_accuracy: 0.9734\n",
      "Epoch 98/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.6785e-04 - accuracy: 0.9999 - val_loss: 0.6534 - val_accuracy: 0.9734\n",
      "Epoch 99/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.1448e-04 - accuracy: 0.9999 - val_loss: 0.6148 - val_accuracy: 0.9751\n",
      "Epoch 100/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 6.8067e-04 - accuracy: 0.9999 - val_loss: 0.6202 - val_accuracy: 0.9739\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "rho = 0.01\n",
    "# rho = 0.99\n",
    "\n",
    "mlp_rmsprop_1.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=rho),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history = mlp_rmsprop_1.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_RMSProp_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer_1 (Dense)      (None, 128)               100480    \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 256)               33024     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136,074\n",
      "Trainable params: 136,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# network params\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 256\n",
    "\n",
    "# create model\n",
    "mlp_rmsprop_2 = keras.Sequential(name=\"MLP_RMSProp_2\")\n",
    "mlp_rmsprop_2.add(Input(shape=(num_features,)))\n",
    "mlp_rmsprop_2.add(keras.layers.Dense(name=\"hidden_layer_1\", units=n_hidden_1, activation=\"relu\"))\n",
    "mlp_rmsprop_2.add(keras.layers.Dense(name=\"hidden_layer_2\", units=n_hidden_2, activation=\"relu\"))\n",
    "mlp_rmsprop_2.add(keras.layers.Dense(name=\"output_layer\", units=num_classes, activation=\"softmax\"))\n",
    "\n",
    "mlp_rmsprop_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.2934 - accuracy: 0.9099 - val_loss: 0.1595 - val_accuracy: 0.9514\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.1194 - accuracy: 0.9639 - val_loss: 0.1148 - val_accuracy: 0.9652\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0842 - accuracy: 0.9742 - val_loss: 0.0981 - val_accuracy: 0.9713\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0629 - accuracy: 0.9806 - val_loss: 0.0828 - val_accuracy: 0.9756\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0488 - accuracy: 0.9843 - val_loss: 0.0898 - val_accuracy: 0.9729\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0401 - accuracy: 0.9873 - val_loss: 0.0900 - val_accuracy: 0.9743\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.9911 - val_loss: 0.0848 - val_accuracy: 0.9761\n",
      "Epoch 8/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 0.0817 - val_accuracy: 0.9776\n",
      "Epoch 9/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 0.0776 - val_accuracy: 0.9801\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0984 - val_accuracy: 0.9748\n",
      "Epoch 11/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.0978 - val_accuracy: 0.9766\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0846 - val_accuracy: 0.9803\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.1150 - val_accuracy: 0.9746\n",
      "Epoch 14/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0979 - val_accuracy: 0.9776\n",
      "Epoch 15/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.1024 - val_accuracy: 0.9787\n",
      "Epoch 16/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0963 - val_accuracy: 0.9803\n",
      "Epoch 17/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.1003 - val_accuracy: 0.9802\n",
      "Epoch 18/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.1045 - val_accuracy: 0.9791\n",
      "Epoch 19/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.1097 - val_accuracy: 0.9791\n",
      "Epoch 20/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.1073 - val_accuracy: 0.9803\n",
      "Epoch 21/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 0.1225 - val_accuracy: 0.9774\n",
      "Epoch 22/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.1354 - val_accuracy: 0.9754\n",
      "Epoch 23/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1331 - val_accuracy: 0.9772\n",
      "Epoch 24/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.1213 - val_accuracy: 0.9801\n",
      "Epoch 25/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.1229 - val_accuracy: 0.9796\n",
      "Epoch 26/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.1317 - val_accuracy: 0.9801\n",
      "Epoch 27/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1390 - val_accuracy: 0.9776\n",
      "Epoch 28/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.1290 - val_accuracy: 0.9796\n",
      "Epoch 29/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.1526 - val_accuracy: 0.9766\n",
      "Epoch 30/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.1379 - val_accuracy: 0.9794\n",
      "Epoch 31/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.1288 - val_accuracy: 0.9798\n",
      "Epoch 32/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.1376 - val_accuracy: 0.9798\n",
      "Epoch 33/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.1646 - val_accuracy: 0.9756\n",
      "Epoch 34/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.1384 - val_accuracy: 0.9791\n",
      "Epoch 35/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.1407 - val_accuracy: 0.9795\n",
      "Epoch 36/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.1434 - val_accuracy: 0.9799\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.2108 - val_accuracy: 0.9719\n",
      "Epoch 38/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.1460 - val_accuracy: 0.9791\n",
      "Epoch 39/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1704 - val_accuracy: 0.9765\n",
      "Epoch 40/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.1386 - val_accuracy: 0.9799\n",
      "Epoch 41/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 6.7858e-04 - accuracy: 0.9998 - val_loss: 0.1729 - val_accuracy: 0.9781\n",
      "Epoch 42/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1798 - val_accuracy: 0.9763\n",
      "Epoch 43/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1755 - val_accuracy: 0.9770\n",
      "Epoch 44/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1620 - val_accuracy: 0.9786\n",
      "Epoch 45/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.1633 - val_accuracy: 0.9784\n",
      "Epoch 46/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.1742 - val_accuracy: 0.9777\n",
      "Epoch 47/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.1657 - val_accuracy: 0.9774\n",
      "Epoch 48/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 5.2680e-04 - accuracy: 0.9999 - val_loss: 0.1766 - val_accuracy: 0.9759\n",
      "Epoch 49/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.1573 - val_accuracy: 0.9784\n",
      "Epoch 50/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1925 - val_accuracy: 0.9769\n",
      "Epoch 51/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.1896 - val_accuracy: 0.9765\n",
      "Epoch 52/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.1732 - val_accuracy: 0.9789\n",
      "Epoch 53/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.1719 - val_accuracy: 0.9794\n",
      "Epoch 54/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.1790 - val_accuracy: 0.9792\n",
      "Epoch 55/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.2324 - val_accuracy: 0.9749\n",
      "Epoch 56/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.1864 - val_accuracy: 0.9798\n",
      "Epoch 57/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.2048 - val_accuracy: 0.9781\n",
      "Epoch 58/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.1808 - val_accuracy: 0.9796\n",
      "Epoch 59/100\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.1990 - val_accuracy: 0.9784\n",
      "Epoch 60/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.2063 - val_accuracy: 0.9761\n",
      "Epoch 61/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1847 - val_accuracy: 0.9798\n",
      "Epoch 62/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.1815 - val_accuracy: 0.9789\n",
      "Epoch 63/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 3.7550e-04 - accuracy: 0.9999 - val_loss: 0.1804 - val_accuracy: 0.9799\n",
      "Epoch 64/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.6879e-04 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9803\n",
      "Epoch 65/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 8.0040e-06 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9802\n",
      "Epoch 66/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.2408 - val_accuracy: 0.9739\n",
      "Epoch 67/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1847 - val_accuracy: 0.9801\n",
      "Epoch 68/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.2009 - val_accuracy: 0.9776\n",
      "Epoch 69/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.2238 - val_accuracy: 0.9761\n",
      "Epoch 70/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1927 - val_accuracy: 0.9796\n",
      "Epoch 71/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 8.6488e-04 - accuracy: 0.9998 - val_loss: 0.3258 - val_accuracy: 0.9697\n",
      "Epoch 72/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.2035 - val_accuracy: 0.9777\n",
      "Epoch 73/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 7.3127e-04 - accuracy: 0.9997 - val_loss: 0.2075 - val_accuracy: 0.9790\n",
      "Epoch 74/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.2114 - val_accuracy: 0.9794\n",
      "Epoch 75/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.2019 - val_accuracy: 0.9793\n",
      "Epoch 76/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.2077 - val_accuracy: 0.9796\n",
      "Epoch 77/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.2092 - val_accuracy: 0.9789\n",
      "Epoch 78/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.2031 - val_accuracy: 0.9786\n",
      "Epoch 79/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.2106 - val_accuracy: 0.9799\n",
      "Epoch 80/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.2069 - val_accuracy: 0.9794\n",
      "Epoch 81/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 7.6381e-04 - accuracy: 0.9998 - val_loss: 0.2028 - val_accuracy: 0.9803\n",
      "Epoch 82/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.2196 - val_accuracy: 0.9784\n",
      "Epoch 83/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.2165 - val_accuracy: 0.9797\n",
      "Epoch 84/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.2045 - val_accuracy: 0.9799\n",
      "Epoch 85/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 3.5804e-04 - accuracy: 0.9999 - val_loss: 0.2044 - val_accuracy: 0.9801\n",
      "Epoch 86/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 5.6849e-04 - accuracy: 0.9998 - val_loss: 0.2429 - val_accuracy: 0.9759\n",
      "Epoch 87/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.2349 - val_accuracy: 0.9781\n",
      "Epoch 88/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.2158 - val_accuracy: 0.9794\n",
      "Epoch 89/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.2234 - val_accuracy: 0.9781\n",
      "Epoch 90/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.2251 - val_accuracy: 0.9781\n",
      "Epoch 91/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 6.4553e-04 - accuracy: 0.9999 - val_loss: 0.2061 - val_accuracy: 0.9809\n",
      "Epoch 92/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.2389 - val_accuracy: 0.9780\n",
      "Epoch 93/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.2437 - val_accuracy: 0.9778\n",
      "Epoch 94/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 6.6268e-04 - accuracy: 0.9998 - val_loss: 0.2307 - val_accuracy: 0.9773\n",
      "Epoch 95/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.2276 - val_accuracy: 0.9775\n",
      "Epoch 96/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.2394 - val_accuracy: 0.9779\n",
      "Epoch 97/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2078 - val_accuracy: 0.9804\n",
      "Epoch 98/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.0623e-04 - accuracy: 0.9999 - val_loss: 0.2097 - val_accuracy: 0.9806\n",
      "Epoch 99/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.2368 - val_accuracy: 0.9794\n",
      "Epoch 100/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.9706e-04 - accuracy: 0.9999 - val_loss: 0.2236 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "rho = 0.99\n",
    "\n",
    "mlp_rmsprop_2.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=rho),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history = mlp_rmsprop_2.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_SGD_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer_1 (Dense)      (None, 128)               100480    \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 256)               33024     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136,074\n",
      "Trainable params: 136,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import initializers\n",
    "\n",
    "# network params\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 256\n",
    "\n",
    "# create model\n",
    "mlp_sgd_1 = keras.Sequential(name=\"MLP_SGD_1\")\n",
    "mlp_sgd_1.add(Input(shape=(num_features,)))\n",
    "mlp_sgd_1.add(keras.layers.Dense(name=\"hidden_layer_1\", units=n_hidden_1, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=10)))\n",
    "mlp_sgd_1.add(keras.layers.Dense(name=\"hidden_layer_2\", units=n_hidden_2, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=10)))\n",
    "mlp_sgd_1.add(keras.layers.Dense(name=\"output_layer\", units=num_classes, activation=\"softmax\", kernel_initializer=initializers.RandomNormal(mean=10)))\n",
    "\n",
    "mlp_sgd_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2558688000.0000 - accuracy: 0.1105 - val_loss: 2.3021 - val_accuracy: 0.1144\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3019 - accuracy: 0.1121 - val_loss: 2.3017 - val_accuracy: 0.1144\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3016 - accuracy: 0.1121 - val_loss: 2.3015 - val_accuracy: 0.1144\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3015 - accuracy: 0.1121 - val_loss: 2.3014 - val_accuracy: 0.1144\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3014 - accuracy: 0.1121 - val_loss: 2.3013 - val_accuracy: 0.1144\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3013 - accuracy: 0.1121 - val_loss: 2.3012 - val_accuracy: 0.1144\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3013 - accuracy: 0.1121 - val_loss: 2.3012 - val_accuracy: 0.1144\n",
      "Epoch 8/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3012 - val_accuracy: 0.1144\n",
      "Epoch 9/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3012 - val_accuracy: 0.1144\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 11/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 14/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 15/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 16/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 17/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 18/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 19/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 20/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 21/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 22/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 23/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 24/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 25/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 26/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 27/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 28/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 29/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 30/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 31/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 32/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 33/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 34/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 35/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 36/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 38/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 39/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 40/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 41/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 42/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 43/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 44/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 45/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 46/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 47/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 48/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 49/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 50/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 51/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 52/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 53/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 54/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 55/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 56/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 57/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 58/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 59/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 60/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 61/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 62/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 63/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 64/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 65/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 66/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 67/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 68/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 69/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 70/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 71/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 72/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 73/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 74/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 75/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 76/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 77/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 78/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 79/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 80/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 81/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 82/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 83/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 84/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 85/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 86/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 87/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 88/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 89/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 90/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 91/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 92/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 93/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 94/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 95/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 96/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 97/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 98/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 99/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 100/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "mlp_sgd_1.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history = mlp_sgd_1.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_SGD_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer_1 (Dense)      (None, 128)               100480    \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 256)               33024     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136,074\n",
      "Trainable params: 136,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# network params\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 256\n",
    "a_reg = 0.1\n",
    "\n",
    "# create model\n",
    "mlp_sgd_2 = keras.Sequential(name=\"MLP_SGD_2\")\n",
    "mlp_sgd_2.add(Input(shape=(num_features,)))\n",
    "mlp_sgd_2.add(keras.layers.Dense(name=\"hidden_layer_1\", units=n_hidden_1, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=10), kernel_regularizer=regularizers.l2(a_reg)))\n",
    "mlp_sgd_2.add(keras.layers.Dense(name=\"hidden_layer_2\", units=n_hidden_2, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=10), kernel_regularizer=regularizers.l2(a_reg)))\n",
    "mlp_sgd_2.add(keras.layers.Dense(name=\"output_layer\", units=num_classes, activation=\"softmax\", kernel_initializer=initializers.RandomNormal(mean=10), kernel_regularizer=regularizers.l2(a_reg)))\n",
    "\n",
    "mlp_sgd_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1792158859264.0000 - accuracy: 0.1119 - val_loss: 1130632183808.0000 - val_accuracy: 0.1144\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 754727714816.0000 - accuracy: 0.1121 - val_loss: 470433169408.0000 - val_accuracy: 0.1144\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 314027114496.0000 - accuracy: 0.1121 - val_loss: 195738042368.0000 - val_accuracy: 0.1144\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 130660474880.0000 - accuracy: 0.1121 - val_loss: 81442693120.0000 - val_accuracy: 0.1144\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 54365245440.0000 - accuracy: 0.1121 - val_loss: 33886701568.0000 - val_accuracy: 0.1144\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 22620305408.0000 - accuracy: 0.1121 - val_loss: 14099590144.0000 - val_accuracy: 0.1144\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 9411862528.0000 - accuracy: 0.1121 - val_loss: 5866556928.0000 - val_accuracy: 0.1144\n",
      "Epoch 8/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 3916089600.0000 - accuracy: 0.1121 - val_loss: 2440961536.0000 - val_accuracy: 0.1144\n",
      "Epoch 9/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1629407360.0000 - accuracy: 0.1121 - val_loss: 1015635648.0000 - val_accuracy: 0.1144\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 677964032.0000 - accuracy: 0.1121 - val_loss: 422585760.0000 - val_accuracy: 0.1144\n",
      "Epoch 11/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 282087488.0000 - accuracy: 0.1121 - val_loss: 175829568.0000 - val_accuracy: 0.1144\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 117371072.0000 - accuracy: 0.1121 - val_loss: 73159184.0000 - val_accuracy: 0.1144\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 48835776.0000 - accuracy: 0.1121 - val_loss: 30440098.0000 - val_accuracy: 0.1144\n",
      "Epoch 14/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 20319594.0000 - accuracy: 0.1121 - val_loss: 12665531.0000 - val_accuracy: 0.1144\n",
      "Epoch 15/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 8454583.0000 - accuracy: 0.1121 - val_loss: 5269876.0000 - val_accuracy: 0.1144\n",
      "Epoch 16/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 3517787.2500 - accuracy: 0.1121 - val_loss: 2192693.7500 - val_accuracy: 0.1144\n",
      "Epoch 17/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1463682.8750 - accuracy: 0.1121 - val_loss: 912337.1250 - val_accuracy: 0.1144\n",
      "Epoch 18/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 609010.8125 - accuracy: 0.1121 - val_loss: 379606.8125 - val_accuracy: 0.1144\n",
      "Epoch 19/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 253398.7812 - accuracy: 0.1121 - val_loss: 157948.3594 - val_accuracy: 0.1144\n",
      "Epoch 20/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 105435.5547 - accuracy: 0.1121 - val_loss: 65720.5000 - val_accuracy: 0.1144\n",
      "Epoch 21/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 43870.9844 - accuracy: 0.1121 - val_loss: 27346.3594 - val_accuracy: 0.1144\n",
      "Epoch 22/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 18255.2070 - accuracy: 0.1121 - val_loss: 11379.6201 - val_accuracy: 0.1144\n",
      "Epoch 23/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 7596.9692 - accuracy: 0.1121 - val_loss: 4736.1768 - val_accuracy: 0.1144\n",
      "Epoch 24/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 3162.2947 - accuracy: 0.1121 - val_loss: 1971.9734 - val_accuracy: 0.1144\n",
      "Epoch 25/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1317.1117 - accuracy: 0.1121 - val_loss: 821.8430 - val_accuracy: 0.1144\n",
      "Epoch 26/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 549.3679 - accuracy: 0.1121 - val_loss: 343.2963 - val_accuracy: 0.1144\n",
      "Epoch 27/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 229.9248 - accuracy: 0.1121 - val_loss: 144.1825 - val_accuracy: 0.1144\n",
      "Epoch 28/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 97.0109 - accuracy: 0.1121 - val_loss: 61.3351 - val_accuracy: 0.1144\n",
      "Epoch 29/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 41.7080 - accuracy: 0.1121 - val_loss: 26.8640 - val_accuracy: 0.1144\n",
      "Epoch 30/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 18.6976 - accuracy: 0.1121 - val_loss: 12.5213 - val_accuracy: 0.1144\n",
      "Epoch 31/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 9.1234 - accuracy: 0.1121 - val_loss: 6.5535 - val_accuracy: 0.1144\n",
      "Epoch 32/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 5.1398 - accuracy: 0.1121 - val_loss: 4.0705 - val_accuracy: 0.1144\n",
      "Epoch 33/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 3.4823 - accuracy: 0.1121 - val_loss: 3.0373 - val_accuracy: 0.1144\n",
      "Epoch 34/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.7926 - accuracy: 0.1121 - val_loss: 2.6074 - val_accuracy: 0.1144\n",
      "Epoch 35/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.5056 - accuracy: 0.1121 - val_loss: 2.4286 - val_accuracy: 0.1144\n",
      "Epoch 36/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3863 - accuracy: 0.1121 - val_loss: 2.3541 - val_accuracy: 0.1144\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3366 - accuracy: 0.1121 - val_loss: 2.3232 - val_accuracy: 0.1144\n",
      "Epoch 38/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3159 - accuracy: 0.1121 - val_loss: 2.3103 - val_accuracy: 0.1144\n",
      "Epoch 39/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3073 - accuracy: 0.1121 - val_loss: 2.3049 - val_accuracy: 0.1144\n",
      "Epoch 40/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3037 - accuracy: 0.1121 - val_loss: 2.3027 - val_accuracy: 0.1144\n",
      "Epoch 41/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3022 - accuracy: 0.1121 - val_loss: 2.3018 - val_accuracy: 0.1144\n",
      "Epoch 42/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3016 - accuracy: 0.1121 - val_loss: 2.3014 - val_accuracy: 0.1144\n",
      "Epoch 43/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3014 - accuracy: 0.1121 - val_loss: 2.3012 - val_accuracy: 0.1144\n",
      "Epoch 44/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3013 - accuracy: 0.1121 - val_loss: 2.3012 - val_accuracy: 0.1144\n",
      "Epoch 45/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 46/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 47/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 48/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 49/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 50/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 51/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 52/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 53/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 54/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 55/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 56/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 57/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 58/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 59/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 60/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 61/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 62/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 63/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 64/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 65/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 66/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 67/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 68/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 69/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 70/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 71/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 72/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 73/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 74/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 75/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 76/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 77/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 78/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 79/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 80/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 81/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 82/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 83/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 84/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 85/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 86/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 87/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 88/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 89/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 90/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 91/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 92/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 93/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 94/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 95/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 96/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 97/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 98/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 99/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n",
      "Epoch 100/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.3012 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1144\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "mlp_sgd_2.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history = mlp_sgd_2.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_SGD_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer_1 (Dense)      (None, 128)               100480    \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 256)               33024     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136,074\n",
      "Trainable params: 136,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# network params\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 256\n",
    "a_reg = 0.01\n",
    "\n",
    "# create model\n",
    "mlp_sgd_3 = keras.Sequential(name=\"MLP_SGD_3\")\n",
    "mlp_sgd_3.add(Input(shape=(num_features,)))\n",
    "mlp_sgd_3.add(keras.layers.Dense(name=\"hidden_layer_1\", units=n_hidden_1, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=10), kernel_regularizer=regularizers.l2(a_reg)))\n",
    "mlp_sgd_3.add(keras.layers.Dense(name=\"hidden_layer_2\", units=n_hidden_2, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=10), kernel_regularizer=regularizers.l2(a_reg)))\n",
    "mlp_sgd_3.add(keras.layers.Dense(name=\"output_layer\", units=num_classes, activation=\"softmax\", kernel_initializer=initializers.RandomNormal(mean=10), kernel_regularizer=regularizers.l2(a_reg)))\n",
    "\n",
    "mlp_sgd_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 244848492544.0000 - accuracy: 0.1110 - val_loss: 233540976640.0000 - val_accuracy: 0.1144\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 223658983424.0000 - accuracy: 0.1121 - val_loss: 213951479808.0000 - val_accuracy: 0.1144\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 204898254848.0000 - accuracy: 0.1121 - val_loss: 196005068800.0000 - val_accuracy: 0.1144\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 187711307776.0000 - accuracy: 0.1121 - val_loss: 179563986944.0000 - val_accuracy: 0.1144\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 171965972480.0000 - accuracy: 0.1121 - val_loss: 164502142976.0000 - val_accuracy: 0.1144\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 157541285888.0000 - accuracy: 0.1121 - val_loss: 150703456256.0000 - val_accuracy: 0.1144\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 144326656000.0000 - accuracy: 0.1121 - val_loss: 138062331904.0000 - val_accuracy: 0.1144\n",
      "Epoch 8/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 132220346368.0000 - accuracy: 0.1121 - val_loss: 126481514496.0000 - val_accuracy: 0.1144\n",
      "Epoch 9/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 121129639936.0000 - accuracy: 0.1121 - val_loss: 115872235520.0000 - val_accuracy: 0.1144\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 110969159680.0000 - accuracy: 0.1121 - val_loss: 106152755200.0000 - val_accuracy: 0.1144\n",
      "Epoch 11/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 101661016064.0000 - accuracy: 0.1121 - val_loss: 97248591872.0000 - val_accuracy: 0.1144\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 93133586432.0000 - accuracy: 0.1121 - val_loss: 89091276800.0000 - val_accuracy: 0.1144\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 85321498624.0000 - accuracy: 0.1121 - val_loss: 81618264064.0000 - val_accuracy: 0.1144\n",
      "Epoch 14/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 78164656128.0000 - accuracy: 0.1121 - val_loss: 74772103168.0000 - val_accuracy: 0.1144\n",
      "Epoch 15/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 71608131584.0000 - accuracy: 0.1121 - val_loss: 68500082688.0000 - val_accuracy: 0.1144\n",
      "Epoch 16/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 65601585152.0000 - accuracy: 0.1121 - val_loss: 62754308096.0000 - val_accuracy: 0.1144\n",
      "Epoch 17/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 60098887680.0000 - accuracy: 0.1121 - val_loss: 57490370560.0000 - val_accuracy: 0.1144\n",
      "Epoch 18/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 55057752064.0000 - accuracy: 0.1121 - val_loss: 52668055552.0000 - val_accuracy: 0.1144\n",
      "Epoch 19/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 50439450624.0000 - accuracy: 0.1121 - val_loss: 48250224640.0000 - val_accuracy: 0.1144\n",
      "Epoch 20/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 46208557056.0000 - accuracy: 0.1121 - val_loss: 44202975232.0000 - val_accuracy: 0.1144\n",
      "Epoch 21/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 42332545024.0000 - accuracy: 0.1121 - val_loss: 40495190016.0000 - val_accuracy: 0.1144\n",
      "Epoch 22/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 38781673472.0000 - accuracy: 0.1121 - val_loss: 37098389504.0000 - val_accuracy: 0.1144\n",
      "Epoch 23/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 35528617984.0000 - accuracy: 0.1121 - val_loss: 33986574336.0000 - val_accuracy: 0.1144\n",
      "Epoch 24/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 32548468736.0000 - accuracy: 0.1121 - val_loss: 31135756288.0000 - val_accuracy: 0.1144\n",
      "Epoch 25/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 29818265600.0000 - accuracy: 0.1121 - val_loss: 28524056576.0000 - val_accuracy: 0.1144\n",
      "Epoch 26/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 27317102592.0000 - accuracy: 0.1121 - val_loss: 26131433472.0000 - val_accuracy: 0.1144\n",
      "Epoch 27/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 25025705984.0000 - accuracy: 0.1121 - val_loss: 23939514368.0000 - val_accuracy: 0.1144\n",
      "Epoch 28/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 22926538752.0000 - accuracy: 0.1121 - val_loss: 21931444224.0000 - val_accuracy: 0.1144\n",
      "Epoch 29/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 21003442176.0000 - accuracy: 0.1121 - val_loss: 20091830272.0000 - val_accuracy: 0.1144\n",
      "Epoch 30/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 19241658368.0000 - accuracy: 0.1121 - val_loss: 18406506496.0000 - val_accuracy: 0.1144\n",
      "Epoch 31/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 17627648000.0000 - accuracy: 0.1121 - val_loss: 16862546944.0000 - val_accuracy: 0.1144\n",
      "Epoch 32/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 16149025792.0000 - accuracy: 0.1121 - val_loss: 15448100864.0000 - val_accuracy: 0.1144\n",
      "Epoch 33/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 14794437632.0000 - accuracy: 0.1121 - val_loss: 14152305664.0000 - val_accuracy: 0.1144\n",
      "Epoch 34/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 13553466368.0000 - accuracy: 0.1121 - val_loss: 12965202944.0000 - val_accuracy: 0.1144\n",
      "Epoch 35/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 12416589824.0000 - accuracy: 0.1121 - val_loss: 11877677056.0000 - val_accuracy: 0.1144\n",
      "Epoch 36/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 11375080448.0000 - accuracy: 0.1121 - val_loss: 10881366016.0000 - val_accuracy: 0.1144\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 10420928512.0000 - accuracy: 0.1121 - val_loss: 9968623616.0000 - val_accuracy: 0.1144\n",
      "Epoch 38/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 9546812416.0000 - accuracy: 0.1121 - val_loss: 9132448768.0000 - val_accuracy: 0.1144\n",
      "Epoch 39/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 8746015744.0000 - accuracy: 0.1121 - val_loss: 8366416384.0000 - val_accuracy: 0.1144\n",
      "Epoch 40/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 8012394496.0000 - accuracy: 0.1121 - val_loss: 7664632320.0000 - val_accuracy: 0.1144\n",
      "Epoch 41/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 7340313600.0000 - accuracy: 0.1121 - val_loss: 7021721600.0000 - val_accuracy: 0.1144\n",
      "Epoch 42/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 6724596736.0000 - accuracy: 0.1121 - val_loss: 6432729088.0000 - val_accuracy: 0.1144\n",
      "Epoch 43/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 6160532992.0000 - accuracy: 0.1121 - val_loss: 5893147648.0000 - val_accuracy: 0.1144\n",
      "Epoch 44/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 5643786752.0000 - accuracy: 0.1121 - val_loss: 5398824448.0000 - val_accuracy: 0.1144\n",
      "Epoch 45/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 5170381312.0000 - accuracy: 0.1121 - val_loss: 4945968640.0000 - val_accuracy: 0.1144\n",
      "Epoch 46/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 4736684032.0000 - accuracy: 0.1121 - val_loss: 4531094528.0000 - val_accuracy: 0.1144\n",
      "Epoch 47/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 4339365888.0000 - accuracy: 0.1121 - val_loss: 4151023104.0000 - val_accuracy: 0.1144\n",
      "Epoch 48/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 3975378688.0000 - accuracy: 0.1121 - val_loss: 3802835712.0000 - val_accuracy: 0.1144\n",
      "Epoch 49/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 3641919744.0000 - accuracy: 0.1121 - val_loss: 3483849216.0000 - val_accuracy: 0.1144\n",
      "Epoch 50/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 3336432640.0000 - accuracy: 0.1121 - val_loss: 3191620352.0000 - val_accuracy: 0.1144\n",
      "Epoch 51/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 3056572416.0000 - accuracy: 0.1121 - val_loss: 2923905280.0000 - val_accuracy: 0.1144\n",
      "Epoch 52/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2800183296.0000 - accuracy: 0.1121 - val_loss: 2678645504.0000 - val_accuracy: 0.1144\n",
      "Epoch 53/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2565300992.0000 - accuracy: 0.1121 - val_loss: 2453960960.0000 - val_accuracy: 0.1144\n",
      "Epoch 54/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2350122240.0000 - accuracy: 0.1121 - val_loss: 2248120576.0000 - val_accuracy: 0.1144\n",
      "Epoch 55/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2152992000.0000 - accuracy: 0.1121 - val_loss: 2059544960.0000 - val_accuracy: 0.1144\n",
      "Epoch 56/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1972397568.0000 - accuracy: 0.1121 - val_loss: 1886789504.0000 - val_accuracy: 0.1144\n",
      "Epoch 57/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1806952192.0000 - accuracy: 0.1121 - val_loss: 1728523136.0000 - val_accuracy: 0.1144\n",
      "Epoch 58/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1655382784.0000 - accuracy: 0.1121 - val_loss: 1583534848.0000 - val_accuracy: 0.1144\n",
      "Epoch 59/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1516527744.0000 - accuracy: 0.1121 - val_loss: 1450705664.0000 - val_accuracy: 0.1144\n",
      "Epoch 60/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1389320448.0000 - accuracy: 0.1121 - val_loss: 1329020160.0000 - val_accuracy: 0.1144\n",
      "Epoch 61/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1272783616.0000 - accuracy: 0.1121 - val_loss: 1217540224.0000 - val_accuracy: 0.1144\n",
      "Epoch 62/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1166021632.0000 - accuracy: 0.1121 - val_loss: 1115411584.0000 - val_accuracy: 0.1144\n",
      "Epoch 63/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1068214656.0000 - accuracy: 0.1121 - val_loss: 1021850560.0000 - val_accuracy: 0.1144\n",
      "Epoch 64/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 978611584.0000 - accuracy: 0.1121 - val_loss: 936136768.0000 - val_accuracy: 0.1144\n",
      "Epoch 65/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 896524928.0000 - accuracy: 0.1121 - val_loss: 857612736.0000 - val_accuracy: 0.1144\n",
      "Epoch 66/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 821323840.0000 - accuracy: 0.1121 - val_loss: 785675840.0000 - val_accuracy: 0.1144\n",
      "Epoch 67/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 752430720.0000 - accuracy: 0.1121 - val_loss: 719773184.0000 - val_accuracy: 0.1144\n",
      "Epoch 68/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 689316096.0000 - accuracy: 0.1121 - val_loss: 659398144.0000 - val_accuracy: 0.1144\n",
      "Epoch 69/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 631496064.0000 - accuracy: 0.1121 - val_loss: 604086720.0000 - val_accuracy: 0.1144\n",
      "Epoch 70/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 578525504.0000 - accuracy: 0.1121 - val_loss: 553415296.0000 - val_accuracy: 0.1144\n",
      "Epoch 71/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 529998272.0000 - accuracy: 0.1121 - val_loss: 506994720.0000 - val_accuracy: 0.1144\n",
      "Epoch 72/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 485541568.0000 - accuracy: 0.1121 - val_loss: 464467840.0000 - val_accuracy: 0.1144\n",
      "Epoch 73/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 444814080.0000 - accuracy: 0.1121 - val_loss: 425507520.0000 - val_accuracy: 0.1144\n",
      "Epoch 74/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 407502720.0000 - accuracy: 0.1121 - val_loss: 389816096.0000 - val_accuracy: 0.1144\n",
      "Epoch 75/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 373321056.0000 - accuracy: 0.1121 - val_loss: 357117888.0000 - val_accuracy: 0.1144\n",
      "Epoch 76/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 342006592.0000 - accuracy: 0.1121 - val_loss: 327162592.0000 - val_accuracy: 0.1144\n",
      "Epoch 77/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 313318784.0000 - accuracy: 0.1121 - val_loss: 299719712.0000 - val_accuracy: 0.1144\n",
      "Epoch 78/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 287037312.0000 - accuracy: 0.1121 - val_loss: 274579168.0000 - val_accuracy: 0.1144\n",
      "Epoch 79/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 262960432.0000 - accuracy: 0.1121 - val_loss: 251547312.0000 - val_accuracy: 0.1144\n",
      "Epoch 80/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 240903120.0000 - accuracy: 0.1121 - val_loss: 230447120.0000 - val_accuracy: 0.1144\n",
      "Epoch 81/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 220696176.0000 - accuracy: 0.1121 - val_loss: 211117072.0000 - val_accuracy: 0.1144\n",
      "Epoch 82/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 202183840.0000 - accuracy: 0.1121 - val_loss: 193408416.0000 - val_accuracy: 0.1144\n",
      "Epoch 83/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 185224496.0000 - accuracy: 0.1121 - val_loss: 177185216.0000 - val_accuracy: 0.1144\n",
      "Epoch 84/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 169687776.0000 - accuracy: 0.1121 - val_loss: 162322816.0000 - val_accuracy: 0.1144\n",
      "Epoch 85/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 155454208.0000 - accuracy: 0.1121 - val_loss: 148706944.0000 - val_accuracy: 0.1144\n",
      "Epoch 86/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 142414576.0000 - accuracy: 0.1121 - val_loss: 136233440.0000 - val_accuracy: 0.1144\n",
      "Epoch 87/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 130468776.0000 - accuracy: 0.1121 - val_loss: 124806096.0000 - val_accuracy: 0.1144\n",
      "Epoch 88/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 119524928.0000 - accuracy: 0.1121 - val_loss: 114337232.0000 - val_accuracy: 0.1144\n",
      "Epoch 89/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 109499112.0000 - accuracy: 0.1121 - val_loss: 104746504.0000 - val_accuracy: 0.1144\n",
      "Epoch 90/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 100314208.0000 - accuracy: 0.1121 - val_loss: 95960264.0000 - val_accuracy: 0.1144\n",
      "Epoch 91/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 91899800.0000 - accuracy: 0.1121 - val_loss: 87911096.0000 - val_accuracy: 0.1144\n",
      "Epoch 92/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 84191168.0000 - accuracy: 0.1121 - val_loss: 80537072.0000 - val_accuracy: 0.1144\n",
      "Epoch 93/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 77129152.0000 - accuracy: 0.1121 - val_loss: 73781504.0000 - val_accuracy: 0.1144\n",
      "Epoch 94/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 70659504.0000 - accuracy: 0.1121 - val_loss: 67592688.0000 - val_accuracy: 0.1144\n",
      "Epoch 95/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 64732516.0000 - accuracy: 0.1121 - val_loss: 61922896.0000 - val_accuracy: 0.1144\n",
      "Epoch 96/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 59302712.0000 - accuracy: 0.1121 - val_loss: 56728808.0000 - val_accuracy: 0.1144\n",
      "Epoch 97/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 54328360.0000 - accuracy: 0.1121 - val_loss: 51970316.0000 - val_accuracy: 0.1144\n",
      "Epoch 98/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 49771264.0000 - accuracy: 0.1121 - val_loss: 47611032.0000 - val_accuracy: 0.1144\n",
      "Epoch 99/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 45596400.0000 - accuracy: 0.1121 - val_loss: 43617392.0000 - val_accuracy: 0.1144\n",
      "Epoch 100/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 41771728.0000 - accuracy: 0.1121 - val_loss: 39958688.0000 - val_accuracy: 0.1144\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "mlp_sgd_3.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history = mlp_sgd_3.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_SGD_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer_1 (Dense)      (None, 128)               100480    \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 256)               33024     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136,074\n",
      "Trainable params: 136,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# network params\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 256\n",
    "a_reg = 0.001\n",
    "\n",
    "# create model\n",
    "mlp_sgd_4 = keras.Sequential(name=\"MLP_SGD_4\")\n",
    "mlp_sgd_4.add(Input(shape=(num_features,)))\n",
    "mlp_sgd_4.add(keras.layers.Dense(name=\"hidden_layer_1\", units=n_hidden_1, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=10), kernel_regularizer=regularizers.l2(a_reg)))\n",
    "mlp_sgd_4.add(keras.layers.Dense(name=\"hidden_layer_2\", units=n_hidden_2, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=10), kernel_regularizer=regularizers.l2(a_reg)))\n",
    "mlp_sgd_4.add(keras.layers.Dense(name=\"output_layer\", units=num_classes, activation=\"softmax\", kernel_initializer=initializers.RandomNormal(mean=10), kernel_regularizer=regularizers.l2(a_reg)))\n",
    "\n",
    "mlp_sgd_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 39302426624.0000 - accuracy: 0.1112 - val_loss: 35920809984.0000 - val_accuracy: 0.1144\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 35764826112.0000 - accuracy: 0.1121 - val_loss: 35607515136.0000 - val_accuracy: 0.1144\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 35452899328.0000 - accuracy: 0.1121 - val_loss: 35296915456.0000 - val_accuracy: 0.1144\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 35143671808.0000 - accuracy: 0.1121 - val_loss: 34989051904.0000 - val_accuracy: 0.1144\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 34837159936.0000 - accuracy: 0.1121 - val_loss: 34683887616.0000 - val_accuracy: 0.1144\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 34533314560.0000 - accuracy: 0.1121 - val_loss: 34381377536.0000 - val_accuracy: 0.1144\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 34232125440.0000 - accuracy: 0.1121 - val_loss: 34081511424.0000 - val_accuracy: 0.1144\n",
      "Epoch 8/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 33933561856.0000 - accuracy: 0.1121 - val_loss: 33784297472.0000 - val_accuracy: 0.1144\n",
      "Epoch 9/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 33637595136.0000 - accuracy: 0.1121 - val_loss: 33489643520.0000 - val_accuracy: 0.1144\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 33344212992.0000 - accuracy: 0.1121 - val_loss: 33197524992.0000 - val_accuracy: 0.1144\n",
      "Epoch 11/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 33053396992.0000 - accuracy: 0.1121 - val_loss: 32907986944.0000 - val_accuracy: 0.1144\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 32765124608.0000 - accuracy: 0.1121 - val_loss: 32620972032.0000 - val_accuracy: 0.1144\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 32479342592.0000 - accuracy: 0.1121 - val_loss: 32336478208.0000 - val_accuracy: 0.1144\n",
      "Epoch 14/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 32196057088.0000 - accuracy: 0.1121 - val_loss: 32054441984.0000 - val_accuracy: 0.1144\n",
      "Epoch 15/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 31915249664.0000 - accuracy: 0.1121 - val_loss: 31774865408.0000 - val_accuracy: 0.1144\n",
      "Epoch 16/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 31636893696.0000 - accuracy: 0.1121 - val_loss: 31497742336.0000 - val_accuracy: 0.1144\n",
      "Epoch 17/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 31360956416.0000 - accuracy: 0.1121 - val_loss: 31223019520.0000 - val_accuracy: 0.1144\n",
      "Epoch 18/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 31087431680.0000 - accuracy: 0.1121 - val_loss: 30950684672.0000 - val_accuracy: 0.1144\n",
      "Epoch 19/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 30816299008.0000 - accuracy: 0.1121 - val_loss: 30680719360.0000 - val_accuracy: 0.1144\n",
      "Epoch 20/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 30547523584.0000 - accuracy: 0.1121 - val_loss: 30413150208.0000 - val_accuracy: 0.1144\n",
      "Epoch 21/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 30281093120.0000 - accuracy: 0.1121 - val_loss: 30147872768.0000 - val_accuracy: 0.1144\n",
      "Epoch 22/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 30016989184.0000 - accuracy: 0.1121 - val_loss: 29884938240.0000 - val_accuracy: 0.1144\n",
      "Epoch 23/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 29755185152.0000 - accuracy: 0.1121 - val_loss: 29624272896.0000 - val_accuracy: 0.1144\n",
      "Epoch 24/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 29495666688.0000 - accuracy: 0.1121 - val_loss: 29365897216.0000 - val_accuracy: 0.1144\n",
      "Epoch 25/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 29238413312.0000 - accuracy: 0.1121 - val_loss: 29109780480.0000 - val_accuracy: 0.1144\n",
      "Epoch 26/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 28983400448.0000 - accuracy: 0.1121 - val_loss: 28855891968.0000 - val_accuracy: 0.1144\n",
      "Epoch 27/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 28730615808.0000 - accuracy: 0.1121 - val_loss: 28604229632.0000 - val_accuracy: 0.1144\n",
      "Epoch 28/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 28480036864.0000 - accuracy: 0.1121 - val_loss: 28354762752.0000 - val_accuracy: 0.1144\n",
      "Epoch 29/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 28231634944.0000 - accuracy: 0.1121 - val_loss: 28107468800.0000 - val_accuracy: 0.1144\n",
      "Epoch 30/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 27985405952.0000 - accuracy: 0.1121 - val_loss: 27862323200.0000 - val_accuracy: 0.1144\n",
      "Epoch 31/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 27741313024.0000 - accuracy: 0.1121 - val_loss: 27619321856.0000 - val_accuracy: 0.1144\n",
      "Epoch 32/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 27499364352.0000 - accuracy: 0.1121 - val_loss: 27378442240.0000 - val_accuracy: 0.1144\n",
      "Epoch 33/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 27259516928.0000 - accuracy: 0.1121 - val_loss: 27139639296.0000 - val_accuracy: 0.1144\n",
      "Epoch 34/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 27021762560.0000 - accuracy: 0.1121 - val_loss: 26902927360.0000 - val_accuracy: 0.1144\n",
      "Epoch 35/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 26786080768.0000 - accuracy: 0.1121 - val_loss: 26668298240.0000 - val_accuracy: 0.1144\n",
      "Epoch 36/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 26552463360.0000 - accuracy: 0.1121 - val_loss: 26435661824.0000 - val_accuracy: 0.1144\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 26320857088.0000 - accuracy: 0.1121 - val_loss: 26205095936.0000 - val_accuracy: 0.1144\n",
      "Epoch 38/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 26091337728.0000 - accuracy: 0.1121 - val_loss: 25976516608.0000 - val_accuracy: 0.1144\n",
      "Epoch 39/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 25863763968.0000 - accuracy: 0.1121 - val_loss: 25749962752.0000 - val_accuracy: 0.1144\n",
      "Epoch 40/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 25638174720.0000 - accuracy: 0.1121 - val_loss: 25525366784.0000 - val_accuracy: 0.1144\n",
      "Epoch 41/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 25414559744.0000 - accuracy: 0.1121 - val_loss: 25302784000.0000 - val_accuracy: 0.1144\n",
      "Epoch 42/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 25192902656.0000 - accuracy: 0.1121 - val_loss: 25082083328.0000 - val_accuracy: 0.1144\n",
      "Epoch 43/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 24973172736.0000 - accuracy: 0.1121 - val_loss: 24863350784.0000 - val_accuracy: 0.1144\n",
      "Epoch 44/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 24755357696.0000 - accuracy: 0.1121 - val_loss: 24646504448.0000 - val_accuracy: 0.1144\n",
      "Epoch 45/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 24539449344.0000 - accuracy: 0.1121 - val_loss: 24431542272.0000 - val_accuracy: 0.1144\n",
      "Epoch 46/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 24325423104.0000 - accuracy: 0.1121 - val_loss: 24218423296.0000 - val_accuracy: 0.1144\n",
      "Epoch 47/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 24113264640.0000 - accuracy: 0.1121 - val_loss: 24007159808.0000 - val_accuracy: 0.1144\n",
      "Epoch 48/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 23902947328.0000 - accuracy: 0.1121 - val_loss: 23797778432.0000 - val_accuracy: 0.1144\n",
      "Epoch 49/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 23694465024.0000 - accuracy: 0.1121 - val_loss: 23590252544.0000 - val_accuracy: 0.1144\n",
      "Epoch 50/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 23487807488.0000 - accuracy: 0.1121 - val_loss: 23384512512.0000 - val_accuracy: 0.1144\n",
      "Epoch 51/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 23282948096.0000 - accuracy: 0.1121 - val_loss: 23180564480.0000 - val_accuracy: 0.1144\n",
      "Epoch 52/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 23079884800.0000 - accuracy: 0.1121 - val_loss: 22978373632.0000 - val_accuracy: 0.1144\n",
      "Epoch 53/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 22878586880.0000 - accuracy: 0.1121 - val_loss: 22777952256.0000 - val_accuracy: 0.1144\n",
      "Epoch 54/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 22679046144.0000 - accuracy: 0.1121 - val_loss: 22579253248.0000 - val_accuracy: 0.1144\n",
      "Epoch 55/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 22481248256.0000 - accuracy: 0.1121 - val_loss: 22382331904.0000 - val_accuracy: 0.1144\n",
      "Epoch 56/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 22285164544.0000 - accuracy: 0.1121 - val_loss: 22187153408.0000 - val_accuracy: 0.1144\n",
      "Epoch 57/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 22090792960.0000 - accuracy: 0.1121 - val_loss: 21993664512.0000 - val_accuracy: 0.1144\n",
      "Epoch 58/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 21898115072.0000 - accuracy: 0.1121 - val_loss: 21801814016.0000 - val_accuracy: 0.1144\n",
      "Epoch 59/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 21707130880.0000 - accuracy: 0.1121 - val_loss: 21611661312.0000 - val_accuracy: 0.1144\n",
      "Epoch 60/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 21517811712.0000 - accuracy: 0.1121 - val_loss: 21423134720.0000 - val_accuracy: 0.1144\n",
      "Epoch 61/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 21330141184.0000 - accuracy: 0.1121 - val_loss: 21236291584.0000 - val_accuracy: 0.1144\n",
      "Epoch 62/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 21144094720.0000 - accuracy: 0.1121 - val_loss: 21051097088.0000 - val_accuracy: 0.1144\n",
      "Epoch 63/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 20959678464.0000 - accuracy: 0.1121 - val_loss: 20867510272.0000 - val_accuracy: 0.1144\n",
      "Epoch 64/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 20776869888.0000 - accuracy: 0.1121 - val_loss: 20685508608.0000 - val_accuracy: 0.1144\n",
      "Epoch 65/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 20595664896.0000 - accuracy: 0.1121 - val_loss: 20505047040.0000 - val_accuracy: 0.1144\n",
      "Epoch 66/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 20416038912.0000 - accuracy: 0.1121 - val_loss: 20326201344.0000 - val_accuracy: 0.1144\n",
      "Epoch 67/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 20237971456.0000 - accuracy: 0.1121 - val_loss: 20148973568.0000 - val_accuracy: 0.1144\n",
      "Epoch 68/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 20061450240.0000 - accuracy: 0.1121 - val_loss: 19973226496.0000 - val_accuracy: 0.1144\n",
      "Epoch 69/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 19886481408.0000 - accuracy: 0.1121 - val_loss: 19799017472.0000 - val_accuracy: 0.1144\n",
      "Epoch 70/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 19713024000.0000 - accuracy: 0.1121 - val_loss: 19626313728.0000 - val_accuracy: 0.1144\n",
      "Epoch 71/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 19541108736.0000 - accuracy: 0.1121 - val_loss: 19455148032.0000 - val_accuracy: 0.1144\n",
      "Epoch 72/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 19370668032.0000 - accuracy: 0.1121 - val_loss: 19285481472.0000 - val_accuracy: 0.1144\n",
      "Epoch 73/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 19201716224.0000 - accuracy: 0.1121 - val_loss: 19117293568.0000 - val_accuracy: 0.1144\n",
      "Epoch 74/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 19034249216.0000 - accuracy: 0.1121 - val_loss: 18950522880.0000 - val_accuracy: 0.1144\n",
      "Epoch 75/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 18868246528.0000 - accuracy: 0.1121 - val_loss: 18785226752.0000 - val_accuracy: 0.1144\n",
      "Epoch 76/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 18703675392.0000 - accuracy: 0.1121 - val_loss: 18621403136.0000 - val_accuracy: 0.1144\n",
      "Epoch 77/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 18540537856.0000 - accuracy: 0.1121 - val_loss: 18459006976.0000 - val_accuracy: 0.1144\n",
      "Epoch 78/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 18378835968.0000 - accuracy: 0.1121 - val_loss: 18297993216.0000 - val_accuracy: 0.1144\n",
      "Epoch 79/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 18218543104.0000 - accuracy: 0.1121 - val_loss: 18138382336.0000 - val_accuracy: 0.1144\n",
      "Epoch 80/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 18059644928.0000 - accuracy: 0.1121 - val_loss: 17980198912.0000 - val_accuracy: 0.1144\n",
      "Epoch 81/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 17902123008.0000 - accuracy: 0.1121 - val_loss: 17823418368.0000 - val_accuracy: 0.1144\n",
      "Epoch 82/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 17745979392.0000 - accuracy: 0.1121 - val_loss: 17667934208.0000 - val_accuracy: 0.1144\n",
      "Epoch 83/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 17591220224.0000 - accuracy: 0.1121 - val_loss: 17513820160.0000 - val_accuracy: 0.1144\n",
      "Epoch 84/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 17437792256.0000 - accuracy: 0.1121 - val_loss: 17361080320.0000 - val_accuracy: 0.1144\n",
      "Epoch 85/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 17285691392.0000 - accuracy: 0.1121 - val_loss: 17209688064.0000 - val_accuracy: 0.1144\n",
      "Epoch 86/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 17134954496.0000 - accuracy: 0.1121 - val_loss: 17059591168.0000 - val_accuracy: 0.1144\n",
      "Epoch 87/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 16985506816.0000 - accuracy: 0.1121 - val_loss: 16910792704.0000 - val_accuracy: 0.1144\n",
      "Epoch 88/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 16837359616.0000 - accuracy: 0.1121 - val_loss: 16763305984.0000 - val_accuracy: 0.1144\n",
      "Epoch 89/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 16690507776.0000 - accuracy: 0.1121 - val_loss: 16617106432.0000 - val_accuracy: 0.1144\n",
      "Epoch 90/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 16544936960.0000 - accuracy: 0.1121 - val_loss: 16472162304.0000 - val_accuracy: 0.1144\n",
      "Epoch 91/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 16400630784.0000 - accuracy: 0.1121 - val_loss: 16328493056.0000 - val_accuracy: 0.1144\n",
      "Epoch 92/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 16257592320.0000 - accuracy: 0.1121 - val_loss: 16186082304.0000 - val_accuracy: 0.1144\n",
      "Epoch 93/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 16115795968.0000 - accuracy: 0.1121 - val_loss: 16044911616.0000 - val_accuracy: 0.1144\n",
      "Epoch 94/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 15975236608.0000 - accuracy: 0.1121 - val_loss: 15904980992.0000 - val_accuracy: 0.1144\n",
      "Epoch 95/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 15835905024.0000 - accuracy: 0.1121 - val_loss: 15766252544.0000 - val_accuracy: 0.1144\n",
      "Epoch 96/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 15697783808.0000 - accuracy: 0.1121 - val_loss: 15628742656.0000 - val_accuracy: 0.1144\n",
      "Epoch 97/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 15560875008.0000 - accuracy: 0.1121 - val_loss: 15492430848.0000 - val_accuracy: 0.1144\n",
      "Epoch 98/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 15425152000.0000 - accuracy: 0.1121 - val_loss: 15357307904.0000 - val_accuracy: 0.1144\n",
      "Epoch 99/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 15290618880.0000 - accuracy: 0.1121 - val_loss: 15223358464.0000 - val_accuracy: 0.1144\n",
      "Epoch 100/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 15157256192.0000 - accuracy: 0.1121 - val_loss: 15090583552.0000 - val_accuracy: 0.1144\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "mlp_sgd_4.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history = mlp_sgd_4.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_SGD_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer_1 (Dense)      (None, 128)               100480    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                2570      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136,074\n",
      "Trainable params: 136,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# network params\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 256\n",
    "a_reg = 0.01\n",
    "dropout_prob = 0.3\n",
    "# create model\n",
    "mlp_sgd_5 = keras.Sequential(name=\"MLP_SGD_5\")\n",
    "mlp_sgd_5.add(Input(shape=(num_features,)))\n",
    "mlp_sgd_5.add(keras.layers.Dense(name=\"hidden_layer_1\", units=n_hidden_1, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=10), kernel_regularizer=regularizers.l1(a_reg)))\n",
    "mlp_sgd_5.add(tf.keras.layers.Dropout(dropout_prob))\n",
    "mlp_sgd_5.add(keras.layers.Dense(name=\"hidden_layer_2\", units=n_hidden_2, activation=\"relu\", kernel_initializer=initializers.RandomNormal(mean=10), kernel_regularizer=regularizers.l1(a_reg)))\n",
    "mlp_sgd_5.add(tf.keras.layers.Dropout(dropout_prob))\n",
    "mlp_sgd_5.add(keras.layers.Dense(name=\"output_layer\", units=num_classes, activation=\"softmax\", kernel_initializer=initializers.RandomNormal(mean=10), kernel_regularizer=regularizers.l1(a_reg)))\n",
    "mlp_sgd_5.add(tf.keras.layers.Dropout(dropout_prob))\n",
    "\n",
    "mlp_sgd_5.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
