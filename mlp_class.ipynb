{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import utils\n",
    "\n",
    "# MNIST dataset params\n",
    "num_classes = 10 # 0-9 digits\n",
    "num_features = 784 # img shape: 28*28\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train, y_train, X_test, y_test = utils.preprocess(X_train, y_train, X_test, y_test, num_classes, num_features, print_summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network params\n",
    "n_hidden_1 = 128\n",
    "n_hidden_2 = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **$1$. MLP with Adam optimizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $a$. Default Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP_Adam_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden_layer_1 (Dense)      (None, 128)               100480    \n",
      "                                                                 \n",
      " hidden_layer_2 (Dense)      (None, 256)               33024     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136,074\n",
      "Trainable params: 136,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "mlp_adam_1 = utils.create_mlp(\"MLP_Adam_1\", \n",
    "                            n_hidden_1, n_hidden_2, \n",
    "                            num_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.3935 - accuracy: 0.8901 - val_loss: 0.1917 - val_accuracy: 0.9447\n",
      "Epoch 2/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.1493 - accuracy: 0.9550 - val_loss: 0.1386 - val_accuracy: 0.9601\n",
      "Epoch 3/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.1029 - accuracy: 0.9692 - val_loss: 0.1172 - val_accuracy: 0.9648\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0793 - accuracy: 0.9756 - val_loss: 0.1080 - val_accuracy: 0.9683\n",
      "Epoch 5/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0611 - accuracy: 0.9811 - val_loss: 0.0888 - val_accuracy: 0.9731\n",
      "Epoch 6/100\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0492 - accuracy: 0.9854 - val_loss: 0.0907 - val_accuracy: 0.9711\n",
      "Epoch 7/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0389 - accuracy: 0.9880 - val_loss: 0.0937 - val_accuracy: 0.9714\n",
      "Epoch 8/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9903 - val_loss: 0.0833 - val_accuracy: 0.9751\n",
      "Epoch 9/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0273 - accuracy: 0.9919 - val_loss: 0.0894 - val_accuracy: 0.9736\n",
      "Epoch 10/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0215 - accuracy: 0.9937 - val_loss: 0.0847 - val_accuracy: 0.9750\n",
      "Epoch 11/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.0847 - val_accuracy: 0.9755\n",
      "Epoch 12/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 0.0876 - val_accuracy: 0.9759\n",
      "Epoch 13/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.0900 - val_accuracy: 0.9780\n",
      "Epoch 14/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.0914 - val_accuracy: 0.9768\n",
      "Epoch 15/100\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.0952 - val_accuracy: 0.9759\n",
      "Epoch 16/100\n",
      " 21/219 [=>............................] - ETA: 0s - loss: 0.0075 - accuracy: 0.9981"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gitop\\repos\\computational-intelligence\\mlp-class\\mlp_class.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gitop/repos/computational-intelligence/mlp-class/mlp_class.ipynb#ch0000005?line=1'>2</a>\u001b[0m mlp_adam_1\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gitop/repos/computational-intelligence/mlp-class/mlp_class.ipynb#ch0000005?line=2'>3</a>\u001b[0m                 loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mCategoricalCrossentropy(), \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gitop/repos/computational-intelligence/mlp-class/mlp_class.ipynb#ch0000005?line=3'>4</a>\u001b[0m                 metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gitop/repos/computational-intelligence/mlp-class/mlp_class.ipynb#ch0000005?line=5'>6</a>\u001b[0m \u001b[39m# train model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gitop/repos/computational-intelligence/mlp-class/mlp_class.ipynb#ch0000005?line=6'>7</a>\u001b[0m mlp_adam_1_history \u001b[39m=\u001b[39m mlp_adam_1\u001b[39m.\u001b[39;49mfit(X_train, y_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gitop/repos/computational-intelligence/mlp-class/mlp_class.ipynb#ch0000005?line=7'>8</a>\u001b[0m                         validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1208\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1206\u001b[0m callbacks\u001b[39m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1207\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 1208\u001b[0m   \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[0;32m   1209\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1210\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1211\u001b[0m         epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1212\u001b[0m         step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1213\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1214\u001b[0m         _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1215\u001b[0m       callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\keras\\engine\\data_adapter.py:1250\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1248\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1249\u001b[0m   \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1250\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m   1251\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[0;32m   1252\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1253\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1254\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m\n\u001b[0;32m   1255\u001b[0m     original_spe)\n\u001b[0;32m   1257\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:645\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    644\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 645\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m    646\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    647\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:720\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[39m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \n\u001b[0;32m    713\u001b[0m \u001b[39mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[39m the read operation.\u001b[39;00m\n\u001b[0;32m    718\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    719\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mRead\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 720\u001b[0m   value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_variable_op()\n\u001b[0;32m    721\u001b[0m \u001b[39m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    722\u001b[0m \u001b[39m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39midentity(value)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:699\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m       result \u001b[39m=\u001b[39m read_and_set_handle()\n\u001b[0;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 699\u001b[0m   result \u001b[39m=\u001b[39m read_and_set_handle()\n\u001b[0;32m    701\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    702\u001b[0m   \u001b[39m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    703\u001b[0m   \u001b[39m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m   tape\u001b[39m.\u001b[39mrecord_operation(\n\u001b[0;32m    705\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReadVariableOp\u001b[39m\u001b[39m\"\u001b[39m, [result], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle],\n\u001b[0;32m    706\u001b[0m       backward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    707\u001b[0m       forward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:689\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m()\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_and_set_handle\u001b[39m():\n\u001b[1;32m--> 689\u001b[0m   result \u001b[39m=\u001b[39m gen_resource_variable_ops\u001b[39m.\u001b[39;49mread_variable_op(\n\u001b[0;32m    690\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dtype)\n\u001b[0;32m    691\u001b[0m   _maybe_set_handle_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, result)\n\u001b[0;32m    692\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:469\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m    468\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 469\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m    470\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mReadVariableOp\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, resource, \u001b[39m\"\u001b[39;49m\u001b[39mdtype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype)\n\u001b[0;32m    471\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m    472\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "mlp_adam_1.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "mlp_adam_1_history = mlp_adam_1.fit(X_train, y_train, batch_size=256, epochs=100, \n",
    "                        validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "utils.disp_results(mlp_adam_1, X_train, y_train, X_test, y_test, mlp_adam_1_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $b$. $L2$ regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $i)$ $\\;\\alpha=0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_reg = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "mlp_adam_2 = utils.create_mlp(\"MLP_Adam_2\", \n",
    "                            n_hidden_1, n_hidden_2, \n",
    "                            num_features, num_classes, kernel_reg=\"l2\", a_reg=a_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "mlp_adam_2.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "mlp_adam_2_history = mlp_adam_2.fit(X_train, y_train, batch_size=256, epochs=100, \n",
    "                        validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "utils.disp_results(mlp_adam_2, X_train, y_train, X_test, y_test, mlp_adam_2_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ii)$ $\\;\\alpha=0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_reg = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "mlp_adam_3 = utils.create_mlp(\"MLP_Adam_3\", \n",
    "                            n_hidden_1, n_hidden_2, \n",
    "                            num_features, num_classes, kernel_reg=\"l2\", a_reg=a_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "mlp_adam_3.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "mlp_adam_3_history = mlp_adam_3.fit(X_train, y_train, batch_size=256, epochs=100, \n",
    "                        validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "utils.disp_results(mlp_adam_3, X_train, y_train, X_test, y_test, mlp_adam_3_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $iii)$ $\\;\\alpha=0.001$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_reg = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "mlp_adam_4 = utils.create_mlp(\"MLP_Adam_4\", \n",
    "                            n_hidden_1, n_hidden_2, \n",
    "                            num_features, num_classes, kernel_reg=\"l2\", a_reg=a_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "mlp_adam_4.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "mlp_adam_4_history = mlp_adam_4.fit(X_train, y_train, batch_size=256, epochs=100, \n",
    "                        validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "utils.disp_results(mlp_adam_4, X_train, y_train, X_test, y_test, mlp_adam_4_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $c$. $L1$ regularization ($\\alpha=0.01$) & Dropout ($probability=0.3$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_reg = 0.01\n",
    "dropout_prob = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "mlp_adam_5 = utils.create_mlp(\"MLP_Adam_5\", \n",
    "                            n_hidden_1, n_hidden_2, \n",
    "                            num_features, num_classes, kernel_reg=\"l1\", a_reg=a_reg,\n",
    "                            dropout_layers=True, dropout_prob=dropout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "mlp_adam_5.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "mlp_adam_5_history = mlp_adam_5.fit(X_train, y_train, batch_size=256, epochs=100, \n",
    "                        validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "utils.disp_results(mlp_adam_5, X_train, y_train, X_test, y_test, mlp_adam_5_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **$2$. MLP with RMSProp optimizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $a$. Default Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $i)$ $\\;\\rho=0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "mlp_rmsprop_1 = utils.create_mlp(\"MLP_RMSProp_1\", \n",
    "                            n_hidden_1, n_hidden_2, \n",
    "                            num_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "mlp_rmsprop_1.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=rho),\n",
    "                    loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "mlp_rmsprop_1_history = mlp_rmsprop_1.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "utils.disp_results(mlp_rmsprop_1, X_train, y_train, X_test, y_test, mlp_rmsprop_1_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ii)$ $\\;\\rho=0.99$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "mlp_rmsprop_2 = utils.create_mlp(\"MLP_RMSProp_2\", \n",
    "                            n_hidden_1, n_hidden_2, \n",
    "                            num_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "mlp_rmsprop_2.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=rho),\n",
    "                    loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "mlp_rmsprop_2_history = mlp_rmsprop_2.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "utils.disp_results(mlp_rmsprop_2, X_train, y_train, X_test, y_test, mlp_rmsprop_2_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $b$. $L2$ regularization ($\\alpha=0.01$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_reg = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $i)$ $\\;\\rho=0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "mlp_rmsprop_3 = utils.create_mlp(\"MLP_RMSProp_3\", \n",
    "                            n_hidden_1, n_hidden_2, \n",
    "                            num_features, num_classes,\n",
    "                            kernel_reg=\"l2\", a_reg=a_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "mlp_rmsprop_3.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=rho),\n",
    "                    loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "mlp_rmsprop_3_history = mlp_rmsprop_3.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "utils.disp_results(mlp_rmsprop_3, X_train, y_train, X_test, y_test, mlp_rmsprop_3_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ii)$ $\\;\\rho=0.99$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "mlp_rmsprop_4 = utils.create_mlp(\"MLP_RMSProp_4\", \n",
    "                            n_hidden_1, n_hidden_2, \n",
    "                            num_features, num_classes,\n",
    "                            kernel_reg=\"l2\", a_reg=a_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "mlp_rmsprop_4.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=rho),\n",
    "                    loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "mlp_rmsprop_4_history = mlp_rmsprop_4.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "utils.disp_results(mlp_rmsprop_4, X_train, y_train, X_test, y_test, mlp_rmsprop_4_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $c$. $L1$ regularization ($\\alpha=0.01$) & Dropout ($probability=0.3$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_reg = 0.01\n",
    "dropout_prob = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $i)$ $\\;\\rho=0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "mlp_rmsprop_5 = utils.create_mlp(\"MLP_RMSProp_5\", \n",
    "                            n_hidden_1, n_hidden_2, \n",
    "                            num_features, num_classes, kernel_reg=\"l1\", a_reg=a_reg,\n",
    "                            dropout_layers=True, dropout_prob=dropout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "mlp_rmsprop_5.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=rho),\n",
    "                    loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "mlp_rmsprop_5_history = mlp_rmsprop_5.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "utils.disp_results(mlp_rmsprop_5, X_train, y_train, X_test, y_test, mlp_rmsprop_5_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ii)$ $\\;\\rho=0.99$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "mlp_rmsprop_6 = utils.create_mlp(\"MLP_RMSProp_6\", \n",
    "                            n_hidden_1, n_hidden_2, \n",
    "                            num_features, num_classes, kernel_reg=\"l1\", a_reg=a_reg,\n",
    "                            dropout_layers=True, dropout_prob=dropout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "mlp_rmsprop_6.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=rho),\n",
    "                    loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "mlp_rmsprop_6_history = mlp_rmsprop_6.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "utils.disp_results(mlp_rmsprop_6, X_train, y_train, X_test, y_test, mlp_rmsprop_6_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **$3$. MLP with SGD optimizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Weight initializer**: Gaussian distribution, mean = 10*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_mean = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $a$. Default Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "mlp_sgd_1 = utils.create_mlp(\"MLP_SGD_1\", \n",
    "                            n_hidden_1, n_hidden_2, \n",
    "                            num_features, num_classes,\n",
    "                            gaussian_init=True, gaussian_mean=gaussian_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "mlp_sgd_1.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "mlp_sgd_1_history = mlp_sgd_1.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "utils.disp_results(mlp_sgd_1, X_train, y_train, X_test, y_test, mlp_sgd_1_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $b$. $L2$ regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $i)$ $\\;\\alpha=0.1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_reg = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "mlp_sgd_2 = utils.create_mlp(\"MLP_SGD_2\", \n",
    "                            n_hidden_1, n_hidden_2, \n",
    "                            num_features, num_classes,\n",
    "                            gaussian_init=True, gaussian_mean=gaussian_mean,\n",
    "                            kernel_reg=\"l2\", a_reg=a_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "mlp_sgd_2.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "mlp_sgd_2_history = mlp_sgd_2.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "utils.disp_results(mlp_sgd_2, X_train, y_train, X_test, y_test, mlp_sgd_2_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ii)$ $\\;\\alpha=0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_reg = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "mlp_sgd_3 = utils.create_mlp(\"MLP_SGD_3\", \n",
    "                            n_hidden_1, n_hidden_2, \n",
    "                            num_features, num_classes,\n",
    "                            gaussian_init=True, gaussian_mean=gaussian_mean,\n",
    "                            kernel_reg=\"l2\", a_reg=a_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "mlp_sgd_3.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "mlp_sgd_3_history = mlp_sgd_3.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "utils.disp_results(mlp_sgd_3, X_train, y_train, X_test, y_test, mlp_sgd_3_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $c$. $L1$ regularization ($\\alpha=0.01$) & Dropout ($probability=0.3$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_reg = 0.01\n",
    "dropout_prob = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "mlp_sgd_4 = utils.create_mlp(\"MLP_SGD_4\", \n",
    "                            n_hidden_1, n_hidden_2, \n",
    "                            num_features, num_classes,\n",
    "                            gaussian_init=True, gaussian_mean=gaussian_mean,\n",
    "                            kernel_reg=\"l1\", a_reg=a_reg,\n",
    "                            dropout_layers=True, dropout_prob=dropout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "mlp_sgd_4.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "mlp_sgd_4_history = mlp_sgd_4.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "utils.disp_results(mlp_sgd_4, X_train, y_train, X_test, y_test, mlp_sgd_4_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
