{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import regularizers\n",
    "from keras import Input\n",
    "import utils\n",
    "import metrics\n",
    "\n",
    "# MNIST dataset params\n",
    "num_classes = 10 # 0-9 digits\n",
    "num_features = 784 # img shape: 28*28\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# pre-process data\n",
    "X_train, y_train, X_test, y_test = utils.preprocess(X_train, y_train, X_test, y_test, num_classes, num_features, print_summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network loss function\n",
    "loss =tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# network metrics\n",
    "eval_metrics = [metrics.f1]\n",
    "\n",
    "# training batch size\n",
    "batch_size = 256\n",
    "\n",
    "# training epochs\n",
    "epochs = 1000\n",
    "\n",
    "# print options during training\n",
    "verbose = 1\n",
    "\n",
    "# early stopping callback\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **$1$. Fine Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "\n",
    "def build_model(hp):\n",
    "\n",
    "    # hyperparams\n",
    "    n_hidden_1      =   hp.Choice(\"units_1\", [64, 128])\n",
    "    n_hidden_2      =   hp.Choice(\"units_2\", [256, 512])\n",
    "    a_reg           =   hp.Choice(\"a_reg\", [0.1, 0.001, 0.000001])\n",
    "    learning_rate   =   hp.Choice(\"learning_rate\", [0.1, 0.01, 0.001])\n",
    "\n",
    "    # mlp model\n",
    "    mlp_rmsprop_ft = keras.Sequential(name=\"MLP_RMSProp_FT\")\n",
    "\n",
    "    mlp_rmsprop_ft.add(Input(shape=(num_features,)))\n",
    "\n",
    "    mlp_rmsprop_ft.add(keras.layers.Dense(name=\"hidden_layer_1\", units=n_hidden_1, activation=\"relu\", \n",
    "                        kernel_regularizer=regularizers.l2(a_reg), kernel_initializer=initializers.HeNormal()))\n",
    "\n",
    "    mlp_rmsprop_ft.add(keras.layers.Dense(name=\"hidden_layer_2\", units=n_hidden_2, activation=\"relu\", \n",
    "                        kernel_regularizer=regularizers.l2(a_reg), kernel_initializer=initializers.HeNormal()))\n",
    "\n",
    "    mlp_rmsprop_ft.add(keras.layers.Dense(name=\"output_layer\", units=num_classes, activation=\"softmax\", \n",
    "                        kernel_regularizer=regularizers.l2(a_reg), kernel_initializer=initializers.HeNormal()))\n",
    "    \n",
    "    mlp_rmsprop_ft.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "                            loss=loss, \n",
    "                            metrics=eval_metrics)\n",
    "    \n",
    "    return mlp_rmsprop_ft\n",
    "\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=50,\n",
    "    overwrite=True,\n",
    "    directory=\"tuning\",\n",
    "    project_name=\"mlp_tuning\",\n",
    ")\n",
    "\n",
    "# tuner = keras_tuner.RandomSearch(\n",
    "#     hypermodel=build_model,\n",
    "#     objective=\"val_loss\",\n",
    "#     max_trials=12,\n",
    "#     overwrite=True,\n",
    "#     directory=\"tuning\",\n",
    "#     project_name=\"mlp_tuning\",\n",
    "# )\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=verbose, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models()[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "best_model.summary()\n",
    "print(best_hyperparameters.get(\"units_1\"))\n",
    "print(best_hyperparameters.get(\"units_2\"))\n",
    "print(best_hyperparameters.get(\"a_reg\"))\n",
    "print(best_hyperparameters.get(\"learning_rate\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
